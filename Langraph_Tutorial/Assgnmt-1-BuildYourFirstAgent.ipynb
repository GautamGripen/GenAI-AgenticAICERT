{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14e8eaf",
   "metadata": {},
   "source": [
    "###This is Assignment No.1\n",
    "\n",
    "Assignment 1: Build Your First Agent\n",
    "Task:\n",
    "Create a Personal Assistant Agent that can:\n",
    "1. Have basic conversations\n",
    "2. Remember user's name and preferences across sessions\n",
    "3. Perform simple calculations\n",
    "4. Tell current time/date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee2d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install -q langgraph langsmith langchain-openai python-dotenv\n",
    "\n",
    "# Optional: for visualization\n",
    "%pip install -q matplotlib graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437b9fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith setup (optional but recommended for debugging):\n",
      "âœ… LangSmith tracing enabled!\n",
      "ðŸš€ Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from typing import Annotated, Dict, List, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# Set up environment variables\n",
    "def setup_environment():\n",
    "    \"\"\"Setup API keys for the tutorial\"\"\"\n",
    "    \n",
    "    # OpenAI API Key\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        openai_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "        os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "    \n",
    "    # Optional: LangSmith for observability (highly recommended)\n",
    "    if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "        print(\"LangSmith setup (optional but recommended for debugging):\")\n",
    "        langsmith_key = getpass.getpass(\"Enter your LangSmith API Key (or press Enter to skip): \")\n",
    "        if langsmith_key:\n",
    "            os.environ[\"LANGSMITH_API_KEY\"] = langsmith_key\n",
    "            os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "            os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph-Tutorial\"\n",
    "            print(\"âœ… LangSmith tracing enabled!\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Skipping LangSmith setup\")\n",
    "    \n",
    "    print(\"ðŸš€ Environment setup complete!\")\n",
    "\n",
    "# Run setup\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38eaf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… State defined!\n",
      "Our state has one field: 'messages' that will store the conversation history\n",
      "The add_messages function ensures new messages are appended, not replaced\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Define our State - this is the \"memory\" of our agent\n",
    "class State(TypedDict):\n",
    "    # messages will store our conversation history\n",
    "    # add_messages is a special function that appends new messages instead of replacing them\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "print(\"âœ… State defined!\")\n",
    "print(\"Our state has one field: 'messages' that will store the conversation history\")\n",
    "print(\"The add_messages function ensures new messages are appended, not replaced\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd00506",
   "metadata": {},
   "source": [
    "### Step 2: Create the Language Model\n",
    "\n",
    "Now we need an AI model to power our chatbot. We'll use OpenAI's GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0dc3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Language model initialized!\n",
      "Model: gpt-3.5-turbo\n",
      "Test response: Thank you! I appreciate your encouragement. I'll do my best to complete the assignment successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",  # You can also use \"gpt-4\" if you have access\n",
    "    temperature=0.7,        # Controls creativity (0 = deterministic, 1 = very creative)\n",
    ")\n",
    "\n",
    "print(\"âœ… Language model initialized!\")\n",
    "print(f\"Model: {llm.model_name}\")\n",
    "\n",
    "# Let's test it quickly\n",
    "test_response = llm.invoke(\"I see this is your first assignment, Good Luck !!\")\n",
    "print(f\"Test response: {test_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3b474",
   "metadata": {},
   "source": [
    "### Step 3: Create the Chatbot Node\n",
    "\n",
    "A **node** is a function that:\n",
    "1. Takes the current state as input\n",
    "2. Does some work (like calling the LLM)\n",
    "3. Returns updates to the state\n",
    "\n",
    "Let's create our chatbot node:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101b923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chatbot node created!\n",
      "This node will:\n",
      "1. Take the conversation history and user's name from state\n",
      "2. Send it to the LLM\n",
      "3. Return the LLM's response to be added to state\n"
     ]
    }
   ],
   "source": [
    "def chatbot_node(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    The main chatbot node that have basic conversations, processes messages and generates responses.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state containing conversation history and remembers user's name and preferences across sessions.\n",
    "        \n",
    "    Returns:\n",
    "        Dict with new messages to add to state\n",
    "    \"\"\"\n",
    "    # Get the conversation history from state\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Call the LLM with the conversation history\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Return the new message to be added to state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"âœ… Chatbot node created!\")\n",
    "print(\"This node will:\")\n",
    "print(\"1. Take the conversation history and user's name from state\")\n",
    "print(\"2. Send it to the LLM\")\n",
    "print(\"3. Return the LLM's response to be added to state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0547c1d",
   "metadata": {},
   "source": [
    "### Step 4: Build the Graph\n",
    "\n",
    "Now we'll create the graph by:\n",
    "1. Creating a StateGraph\n",
    "2. Adding our chatbot node\n",
    "3. Defining the flow (edges)\n",
    "4. Compiling it into a runnable application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ef30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyDevEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
