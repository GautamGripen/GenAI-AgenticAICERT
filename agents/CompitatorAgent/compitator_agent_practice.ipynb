{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6699eb",
   "metadata": {},
   "source": [
    "### What Are AI Agents? - AI agents are software programs that use artificial intelligence to perform tasks and pursue goals on behalf of users, often with a degree of autonomy. They can reason, plan, and learn, adapting their actions based on data and feedback to achieve their objectives. Unlike traditional AI, which relies on pre-defined rules, AI agents can leverage large language models (LLMs) and other AI/ML tools to understand complex situations and make decisions independently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ed254",
   "metadata": {},
   "source": [
    "# AI Competitor Intelligence Agent Tutorial\n",
    "This notebook demonstrates how to build an AI-powered competitor analysis system.\n",
    "\n",
    "## What we'll learn:\n",
    "1. Setting up API connections (Exa, Firecrawl, OpenAI)\n",
    "2. Finding competitor URLs automatically\n",
    "3. Extracting competitor data from websites\n",
    "4. Generating structured comparison reports\n",
    "5. Creating actionable business insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d04483",
   "metadata": {},
   "source": [
    "#Firecrawl is like a web scrapper. It goes into websites and get the information. (only to the openly available websites !!!, else IP will block) (https://www.firecrawl.dev/signin/password_signin)\n",
    "\n",
    "\n",
    "##Exa is for retrieving any URL & analyse them. Example you give Amazon's URL, Exa will help to get URL of similar websites or its compettitors. (https://docs.exa.ai/reference/getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173fa5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: exa-py==1.7.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: firecrawl-py==1.9.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: duckduckgo-search==7.2.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (7.2.1)\n",
      "Requirement already satisfied: phidata==2.7.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (2.7.3)\n",
      "Requirement already satisfied: streamlit==1.41.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.41.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\miniconda3\\lib\\site-packages (from exa-py==1.7.1->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\miniconda3\\lib\\site-packages (from exa-py==1.7.1->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: openai>=1.10.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from exa-py==1.7.1->-r requirements.txt (line 1)) (1.93.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\miniconda3\\lib\\site-packages (from firecrawl-py==1.9.0->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: websockets in c:\\users\\hp\\miniconda3\\lib\\site-packages (from firecrawl-py==1.9.0->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from firecrawl-py==1.9.0->-r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from firecrawl-py==1.9.0->-r requirements.txt (line 2)) (2.11.7)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from duckduckgo-search==7.2.1->-r requirements.txt (line 3)) (8.2.0)\n",
      "Requirement already satisfied: primp>=0.10.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from duckduckgo-search==7.2.1->-r requirements.txt (line 3)) (0.15.0)\n",
      "Requirement already satisfied: lxml>=5.3.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from duckduckgo-search==7.2.1->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: gitpython in c:\\users\\hp\\miniconda3\\lib\\site-packages (from phidata==2.7.3->-r requirements.txt (line 4)) (3.1.44)\n",
      "Requirement already satisfied: httpx in c:\\users\\hp\\miniconda3\\lib\\site-packages (from phidata==2.7.3->-r requirements.txt (line 4)) (0.28.1)\n",
      "Requirement already satisfied: pydantic-settings in c:\\users\\hp\\miniconda3\\lib\\site-packages (from phidata==2.7.3->-r requirements.txt (line 4)) (2.10.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\miniconda3\\lib\\site-packages (from phidata==2.7.3->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\miniconda3\\lib\\site-packages (from phidata==2.7.3->-r requirements.txt (line 4)) (13.9.4)\n",
      "Requirement already satisfied: tomli in c:\\users\\hp\\miniconda3\\lib\\site-packages (from phidata==2.7.3->-r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: typer in c:\\users\\hp\\miniconda3\\lib\\site-packages (from phidata==2.7.3->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (5.5.2)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (11.3.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (5.29.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (20.0.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (6.0.0)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from streamlit==1.41.1->-r requirements.txt (line 5)) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (4.24.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (1.46.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from click>=8.1.7->duckduckgo-search==7.2.1->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from gitpython->phidata==2.7.3->-r requirements.txt (line 4)) (4.0.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py==1.7.1->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py==1.7.1->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py==1.7.1->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py==1.7.1->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py==1.7.1->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\miniconda3\\lib\\site-packages (from httpx->phidata==2.7.3->-r requirements.txt (line 4)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\miniconda3\\lib\\site-packages (from httpx->phidata==2.7.3->-r requirements.txt (line 4)) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\miniconda3\\lib\\site-packages (from httpx->phidata==2.7.3->-r requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx->phidata==2.7.3->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pydantic>=2.10.3->firecrawl-py==1.9.0->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pydantic>=2.10.3->firecrawl-py==1.9.0->-r requirements.txt (line 2)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pydantic>=2.10.3->firecrawl-py==1.9.0->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->exa-py==1.7.1->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->exa-py==1.7.1->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from rich->phidata==2.7.3->-r requirements.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from rich->phidata==2.7.3->-r requirements.txt (line 4)) (2.19.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from typer->phidata==2.7.3->-r requirements.txt (line 4)) (1.5.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->phidata==2.7.3->-r requirements.txt (line 4)) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (0.26.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->phidata==2.7.3->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit==1.41.1->-r requirements.txt (line 5)) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e5cdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: exa-py in c:\\users\\hp\\miniconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\miniconda3\\lib\\site-packages (from exa-py) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\miniconda3\\lib\\site-packages (from exa-py) (4.12.2)\n",
      "Requirement already satisfied: openai>=1.10.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from exa-py) (1.93.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from openai>=1.10.0->exa-py) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->exa-py) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->exa-py) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->exa-py) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->exa-py) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.10.0->exa-py) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.10.0->exa-py) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.10.0->exa-py) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.10.0->exa-py) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.10.0->exa-py) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai>=1.10.0->exa-py) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install exa-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "502dd2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from exa_py import Exa\n",
    "from phi.agent import Agent\n",
    "from phi.tools.firecrawl import FirecrawlTools\n",
    "from phi.model.openai import OpenAIChat\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "import pandas as pd\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe9ba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”‘ API keys configured\n"
     ]
    }
   ],
   "source": [
    "# Set up API keys (replace with your actual keys)\n",
    "OPENAI_API_KEY = \"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\"\n",
    "FIRECRAWL_API_KEY = \"fc-36525ed263ea4c8a83b6d7f8e15e9bfe\" \n",
    "EXA_API_KEY = \"d8b52aa9-7dce-416b-aa87-1a0fb98dc4d5\"\n",
    "\n",
    "# Initialize Exa client\n",
    "exa = Exa(api_key=EXA_API_KEY)\n",
    "print(\"ðŸ”‘ API keys configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3123dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawling using firecrawl\n",
    "#lets declare tools first\n",
    "firecrawl_tools = FirecrawlTools(\n",
    "    api_key= FIRECRAWL_API_KEY,\n",
    "    scrape= False,\n",
    "    crawl=True,\n",
    "    limit=5\n",
    ")\n",
    "#creating an firecrawl agent\n",
    "#we dont have define schema like in case of function calling, Agent does it here\n",
    "firecrawl_agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4o-mini\", api_key=OPENAI_API_KEY),\n",
    "    tools=[firecrawl_tools, DuckDuckGo()],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4e2697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Agent Initilized successfully\n"
     ]
    }
   ],
   "source": [
    "#Now building a Comparision Agent\n",
    "#whatever infor the firecrawl_agent gets, comparision agent will compare that !!\n",
    "comparision_agent= Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4o-mini\", api_key=OPENAI_API_KEY),\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "print(\"AI Agent Initilized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0679051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_competitor_urls(url=None, description=None):\n",
    "    \"\"\"\n",
    "    Find competitor URLs using Exa's search capabilities\n",
    "    \n",
    "    Args:\n",
    "        url: Company website URL\n",
    "        description: Company description text\n",
    "    \n",
    "    Returns:\n",
    "        List of competitor URLs\n",
    "    \"\"\"\n",
    "    if url:\n",
    "        # Find similar companies based on URL\n",
    "        result = exa.find_similar(\n",
    "            url=url,\n",
    "            num_results=10,\n",
    "            exclude_source_domain=True,\n",
    "            category=\"company\"\n",
    "        )\n",
    "    elif description:\n",
    "        # Search for companies based on description\n",
    "        result = exa.search(\n",
    "            description,\n",
    "            type=\"neural\",\n",
    "            category=\"company\",\n",
    "            use_autoprompt=True,\n",
    "            num_results=10\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Please provide either a URL or a description.\")\n",
    "    \n",
    "    competitor_urls = [item.url for item in result.results]\n",
    "    return competitor_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfecd2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ferrari.com/en-EN/formula1/team',\n",
       " 'https://en.wikipedia.org/wiki/Scuderia_Ferrari',\n",
       " 'https://www.skysports.com/f1/teams/ferrari']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets test the function to get the comparision\n",
    "#It should return the competetor URLs\n",
    "get_competitor_urls(\"https://www.formula1.com/en/teams/ferrari\",\"For many, Ferrari and Formula 1 racing have become inseparable. The only team to have competed in every season since the world championship began, the Prancing Horse has grown from the humble dream of founder Enzo Ferrari to become one of the most iconic and recognised brands in the world. Success came quickly through the likes of Alberto Ascari and John Surtees, and continued â€“ in amongst leaner times â€“ with Niki Lauda in the 1970s and then Michael Schumacher in the 2000s, when Ferrari claimed a then unprecedented five consecutive title doubles, securing their status as the most successful and decorated team in F1 history...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdc665e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found competitors: ['https://www.forumula1.com/', 'https://corp.formula1.com/', 'https://www.motogp.com/', 'https://f1.co.uk/', 'https://www.bbc.com/sport/formula1', 'https://www.autosport.com/f1/', 'https://www.fia.com/', 'https://www.wrc.com/']\n"
     ]
    }
   ],
   "source": [
    "test_url = \"https://www.formula1.com/\"\n",
    "competitors = get_competitor_urls(url=test_url)\n",
    "print(f\"Found competitors: {competitors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample competitor data extracted!\n",
      "Data length: 2518\n"
     ]
    }
   ],
   "source": [
    "## Assignment - Adjust this function to work with the multiple URL (for this we will have to use Loop)\n",
    "#Now lets just try to extract the competitor info\n",
    "\n",
    "def extract_competitor_info(competitor_url: str):\n",
    "    \"\"\"\n",
    "    Extract detailed information from competitor websites\n",
    "    \n",
    "    Args:\n",
    "        competitor_url: URL of competitor website\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with competitor data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use AI agent to crawl and summarize the website\n",
    "        crawl_response = firecrawl_agent.run(f\"Crawl and summarize {competitor_url}\")\n",
    "        crawled_data = crawl_response.content\n",
    "        \n",
    "        return {\n",
    "            \"competitor\": competitor_url,\n",
    "            \"data\": crawled_data\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting info for {competitor_url}: {e}\")\n",
    "        return {\n",
    "            \"competitor\": competitor_url,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Test the function \n",
    "sample_data = extract_competitor_info(competitors[0])\n",
    "print(\"Sample competitor data extracted!\")\n",
    "print(f\"Data length: {len(str(sample_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9680d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'competitor': 'https://www.forumula1.com/', 'data': \"\\nRunning:\\n - crawl_website(url=https://www.forumula1.com/, limit=5)\\n\\n### Summary of FORUMula1.com\\n\\n**General Overview**\\nFORUMula1.com is dedicated to providing the latest news and forums related to Formula 1 and motorsports. The site features articles, opinion pieces, business insights, and merchandise related to F1.\\n\\n**Featured Articles**\\n1. **Hamiltonâ€™s Luck: The Stats**  \\n   A detailed statistical analysis of Lewis Hamilton's performances.  \\n   [Read more](https://www.forumula1.com/news/hamiltons-luck-the-stats/)\\n\\n2. **2014: Review of the Year**  \\n   A retrospective look at the significant events and highlights from the 2014 F1 season.  \\n   [Read more](https://www.forumula1.com/business/flex-mag-powerfully-simple-wordpress-theme/)\\n\\n3. **Julesâ€™ Accident and the Psychology of F1**  \\n   An exploration of the psychological effects of F1 accidents on drivers and teams.  \\n   [Read more](https://www.forumula1.com/sports/only-three-players-have-a-winning-record-against-rafael-nadal/)\\n\\n4. **Button or Magnussen for 2015?**  \\n   Discusses the potential implications of driver changes at McLaren.  \\n   [Read more](https://www.forumula1.com/sports/button-or-magnussen-for-2015/)\\n\\n5. **Seismic Day for F1 Leaves Winners and Losers**  \\n   Insights into a particularly eventful qualifying session.  \\n   [Read more](https://www.forumula1.com/news/seismic-day-f1-leaves-winners-losers/)\\n\\n**Business & Merchandise**\\nThe site offers an official merchandise store to support operations. Recommendations from users might result in new products being added to the store.\\n\\n**Forum Discussions**\\nThe community engages in various discussions ranging from general F1 topics, technical discussions, historical retrospectives, and club-style discussions about racing experiences and opinions.\\n\\n**Experience Days**\\nThe site provides options for fans to engage directly with motorsport through experience days, including driving F1 cars and other motorsport vehicles.\\n\\n**Latest News Highlights**\\n- **Hamiltonâ€™s Luck: The Stats** brought significant user engagement.\\n- **Julesâ€™ Accident** has been a key topic reflecting on driver safety.\\n\\n**Links to Social Media**\\nThe site encourages interaction via its Twitter profile: [@Forumula1](https://twitter.com/forumula1).\\n\\n---\\n\\nThis summary provides a condensed overview of the key features, articles, and user engagement on FORUMula1.com, which serves as a hub for F1 enthusiasts.\"}\n"
     ]
    }
   ],
   "source": [
    "print(sample_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
